{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/faustina/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "word_list = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, kernel)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Tips for Dating Someone with Depression'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_folder = '/Users/faustina/METIS/BOOTCAMPWORK/Project 4/autotherapy/data/scraped_accounts/alyssamariewellness/'\n",
    "ipath = '2017-06-06_07-08-49_UTC'\n",
    "img = cv2.imread(project_folder + ipath + '.jpg')\n",
    "\n",
    "morph = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY, kernel)\n",
    "#print(pytesseract.image_to_string(morph))\n",
    "\n",
    "d = pytesseract.image_to_data(morph, output_type=Output.DICT)\n",
    "words = [w for w in d['text'] if len(w)]\n",
    "' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "noise = cv2.medianBlur(img, 5)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY, kernel)\n",
    "erosion = cv2.erode(gray, kernel, iterations = 1)\n",
    "dilation = cv2.dilate(gray, kernel, iterations = 1)\n",
    "opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n",
    "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "              _/Tips for Dating  Someone with  Depression â€”\n",
      "for dating someone with depression  \n",
      "\n",
      "1\n",
      "                  Tips for Dating  Someone with  Depression\n",
      "for dating someone with depression  \n",
      "\n",
      "2\n",
      "                  Tips for Dating  Someone with  Depression\n",
      "for dating someone with depression  \n",
      "\n",
      "3\n",
      "    Lo oWien  Could make    4, BA                epression\n",
      "lo could make ba expression  \n",
      "\n",
      "4\n",
      "                  Tips for Dating  Someone with  Depression\n",
      "for dating someone with depression  \n",
      "\n",
      "5\n",
      "                       L Wioh y \\  Covld make ) \\  Yow happy: |                 \\ j= Someone with  Depression\n",
      "l with y could make you happy j someone with depression  \n",
      "\n",
      "6\n",
      "                    _- Tips for Dating  _ Someone with  pce S Sion\n",
      "for dating someone with pace s soon  \n",
      "\n",
      "7\n",
      "       \n",
      " \n",
      "\n",
      "8\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, morph in enumerate([noise, gray, erosion, dilation, opening, closing, gradient, tophat, blackhat]): #[gray, thresh, opening, canny, deskewed]:\n",
    "    print(idx)\n",
    "    d = pytesseract.image_to_data(morph, output_type=Output.DICT)\n",
    "    words = [w for w in d['text']]# if len(w) > 2]\n",
    "    print(' '.join(words))\n",
    "    s = ''\n",
    "    for t in words:\n",
    "        try:\n",
    "            t = re.match('(\\w+)', t).group(0)\n",
    "            correction = TextBlob(t.lower()).correct().raw\n",
    "            if correction in word_list:\n",
    "                s += correction + ' '\n",
    "        except:\n",
    "            t = ''\n",
    "    print(s, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "project_folder = os.path.expanduser('../../') # the folder of your project\n",
    "load_dotenv(os.path.join(project_folder, '.env'))\n",
    "\n",
    "GOOGLE_APPLICATION_CREDENTIALS = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "credentials = service_account.Credentials.from_service_account_file(project_folder + GOOGLE_APPLICATION_CREDENTIALS)\n",
    "\n",
    "client_options = {'api_endpoint': 'eu-vision.googleapis.com'}\n",
    "\n",
    "client = vision.ImageAnnotatorClient(client_options=client_options, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts:\n",
      "\n",
      "\"you ARE ALLOWED\n",
      "TO LET GO. BUT\n",
      "WHEN DO - LET\n",
      "you\n",
      "GO WITH KINDNESS.\n",
      "LET GO WITH LOVE.\n",
      "NEVER LET GO WITH\n",
      "HATE IN youR HEART,\n",
      "MB.\n",
      "\"\n",
      "bounds: (110,44),(543,44),(543,578),(110,578)\n",
      "\n",
      "\"you\"\n",
      "bounds: (126,50),(211,48),(212,87),(127,89)\n",
      "\n",
      "\"ARE\"\n",
      "bounds: (212,51),(289,49),(290,75),(213,77)\n",
      "\n",
      "\"ALLOWED\"\n",
      "bounds: (310,49),(503,44),(504,77),(311,82)\n",
      "\n",
      "\"TO\"\n",
      "bounds: (113,116),(196,116),(196,152),(113,152)\n",
      "\n",
      "\"LET\"\n",
      "bounds: (197,120),(266,120),(266,147),(197,147)\n",
      "\n",
      "\"GO.\"\n",
      "bounds: (284,116),(393,116),(393,152),(284,152)\n",
      "\n",
      "\"BUT\"\n",
      "bounds: (395,116),(442,116),(442,152),(395,152)\n",
      "\n",
      "\"WHEN\"\n",
      "bounds: (126,185),(240,183),(240,210),(126,212)\n",
      "\n",
      "\"DO\"\n",
      "bounds: (352,179),(438,178),(439,218),(353,219)\n",
      "\n",
      "\"-\"\n",
      "bounds: (441,177),(486,176),(487,216),(442,217)\n",
      "\n",
      "\"LET\"\n",
      "bounds: (488,176),(534,175),(535,216),(489,217)\n",
      "\n",
      "\"you\"\n",
      "bounds: (274,185),(329,184),(330,231),(275,232)\n",
      "\n",
      "\"GO\"\n",
      "bounds: (119,251),(196,251),(196,286),(119,286)\n",
      "\n",
      "\"WITH\"\n",
      "bounds: (194,256),(281,256),(281,280),(194,280)\n",
      "\n",
      "\"KINDNESS.\"\n",
      "bounds: (314,252),(504,251),(504,282),(314,283)\n",
      "\n",
      "\"LET\"\n",
      "bounds: (117,312),(178,313),(177,342),(116,341)\n",
      "\n",
      "\"GO\"\n",
      "bounds: (200,310),(255,311),(254,345),(199,344)\n",
      "\n",
      "\"WITH\"\n",
      "bounds: (267,315),(358,317),(357,343),(266,341)\n",
      "\n",
      "\"LOVE.\"\n",
      "bounds: (392,316),(493,318),(492,347),(391,345)\n",
      "\n",
      "\"NEVER\"\n",
      "bounds: (116,374),(233,374),(233,405),(116,405)\n",
      "\n",
      "\"LET\"\n",
      "bounds: (268,376),(329,376),(329,409),(268,409)\n",
      "\n",
      "\"GO\"\n",
      "bounds: (348,370),(443,370),(443,409),(348,409)\n",
      "\n",
      "\"WITH\"\n",
      "bounds: (440,378),(535,378),(535,405),(440,405)\n",
      "\n",
      "\"HATE\"\n",
      "bounds: (110,442),(191,443),(191,472),(110,471)\n",
      "\n",
      "\"IN\"\n",
      "bounds: (228,438),(262,438),(262,464),(228,464)\n",
      "\n",
      "\"youR\"\n",
      "bounds: (289,439),(373,440),(372,482),(288,481)\n",
      "\n",
      "\"HEART,\"\n",
      "bounds: (398,442),(537,444),(537,477),(398,475)\n",
      "\n",
      "\"MB.\"\n",
      "bounds: (481,552),(543,552),(543,578),(481,578)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "path = '/Users/faustina/Documents/Instagram/minaa_b/2018-04-22_12-26-34_UTC.jpg'\n",
    "with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "image = vision.types.Image(content=content)\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "print('Texts:')\n",
    "\n",
    "for text in texts:\n",
    "    print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "    print('bounds: {}'.format(','.join(vertices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you ARE ALLOWED\\nTO LET GO. BUT\\nWHEN DO - LET\\nyou\\nGO WITH KINDNESS.\\nLET GO WITH LOVE.\\nNEVER LET GO WITH\\nHATE IN youR HEART,\\nMB.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].description"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
