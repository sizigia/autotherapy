{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nanonets.com/blog/ocr-with-tesseract/\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, kernel)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "noise = cv2.medianBlur(img, 5)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY, kernel)\n",
    "erosion = cv2.erode(gray, kernel, iterations = 1)\n",
    "dilation = cv2.dilate(gray, kernel, iterations = 1)\n",
    "opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n",
    "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, morph in enumerate([noise, gray, erosion, dilation, opening, closing, gradient, tophat, blackhat]): #[gray, thresh, opening, canny, deskewed]:\n",
    "    print(idx)\n",
    "    d = pytesseract.image_to_data(morph, output_type=Output.DICT)\n",
    "    words = [w for w in d['text']]# if len(w) > 2]\n",
    "    print(' '.join(words))\n",
    "    s = ''\n",
    "    for t in words:\n",
    "        try:\n",
    "            t = re.match('(\\w+)', t).group(0)\n",
    "            correction = TextBlob(t.lower()).correct().raw\n",
    "            if correction in word_list:\n",
    "                s += correction + ' '\n",
    "        except:\n",
    "            t = ''\n",
    "    print(s, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "project_folder = os.path.expanduser('../../') # the folder of your project\n",
    "load_dotenv(os.path.join(project_folder, '.env'))\n",
    "\n",
    "GOOGLE_APPLICATION_CREDENTIALS = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "credentials = service_account.Credentials.from_service_account_file(project_folder + GOOGLE_APPLICATION_CREDENTIALS)\n",
    "\n",
    "client_options = {'api_endpoint': 'eu-vision.googleapis.com'}\n",
    "\n",
    "client = vision.ImageAnnotatorClient(client_options=client_options, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "path = '/Users/faustina/Documents/Instagram/minaa_b/2018-04-22_12-26-34_UTC.jpg'\n",
    "with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "image = vision.types.Image(content=content)\n",
    "\n",
    "response = client.text_detection(image=image)\n",
    "texts = response.text_annotations\n",
    "print('Texts:')\n",
    "\n",
    "for text in texts:\n",
    "    print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "    print('bounds: {}'.format(','.join(vertices)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
